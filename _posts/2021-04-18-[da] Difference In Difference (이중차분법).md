---
layout: post
title:  "[da] Difference In Difference (이중차분법)"
date:   2021-04-18T14:25:52-05:00
tags: ab테스트 효과분석 did 이중차분법
categories: For-You
---
DID를 설명하기에 앞서 DID가 활용되는 A/B 테스트에 대해 간단히 알아보자. 

### A/B 테스트
 
A/B 테스트란 모집단을 실험군 (treat)과 대조군 (control)로 나눈 후 특정 정책을 실험군에게만 적용하여 그 정책의 유효성 (효과)을 추정하는 것이다. 즉, 정책의 효과 추정이 A/B 테스트의 목적이다.
실제 비스니스 서비스에서 A/B 테스트를 시행할 때 어려운 점은 크게 두가지로 꼽힌다. 
1. 실험군과 대조군을 동일한 특성을 가지도록 나누기
2. 실험군에게만 정책을 적용하기   

이것들이 왜 어려울까 차례로 얘기를 해보자면, 수많은 특성을 가진 서비스 유저들을 동일한 특성을 가지도록 두 그룹으로 나눈다는 것은 정답이 없는 일이다. 즉, 실험군/대조군의 성비, 나이분포, 거주지 등 고려해야할 것이 한두가지가 아니기 때문이다. 내가 서비스 운영을 위해 A/B 테스트를 세팅할 때 느낀 점은 서비스 유저 풀이 특정 수준을 넘어섰다면 임의로 반을 나누는 것이 가장 명확했다 (!). 즉, 유저에게 부여된 유저키가 있다면 끝자리 기준 홀짝으로 실험군/대조군을 나누는 것이 가장 효과적이란 것을 경험했다. 이것이 모수 통계의 마법이랄까.. 물론. 서비스 유저 풀이 1,000명이 채 안된다면 실험군/대조군 분류에 긴 시간 힘을 쏟아야 한다.

두번째 어려운점은 서비스를 운영해본 실무자라면 이해할 것이다. 특정 정책을 서비스 유저 일부에게만 적용했다가는 자칫 서비스 유저의 부정 동향과 반감을 만들어낼 수 있다. 예를 들어, 캐시백을 3%, 4%, 5% 비율 중 몇 %가 유저의 재구매율을 높일 수 있을까? 당연히 비율이 높은 것이 좋지 않을까라고 생각할 수 있지만, 4% 비율로 지급할 때와 5%로 지급할 때의 재구매율이 큰 차이가 없다면 굳이 5% 비율로 캐시백을 지급할 필요가 없다. 이를 실험하기 위해 A/B 테스트를 한다고 상상해보자. 동일한 금액을 지불하는 유저에게 다른 비율로 캐시백을 지급한다니.. 생각만해도 끔찍하다. 자칫하다간 서비스가 문을 닫아야 할지도 모른다. 이처럼 A/B 테스트에 대한 이론은 이해가 쉽고, 유효성과 효과를 검증하기에 최고의 방법이지만 서비스에 실제로 적용하기는 쉽지 않다.

(간단히 알아보려 했으나 글이 길어졌다.)

### Difference In Difference, DID, 이중차분법

DID란 A/B 테스트 방법 중 하나로, 이름이 거창하지만 우리가 알게 모르게 일상 생활에서도 적용하고 있는 효과 추정 방법이다.
아래 그림 (출처: 위키피디아)으로 설명을 해보자. `Time_1`은 정책 적용 전, `Time_2`는 정책 적용 후를 의미하며 y축은 매출이라 가정하자.
궁극적으로는 `P_2 - Q`가 정책의 효과이고 이를 계산하는 것은 `(P_2 - P_1) - (S_2 - S_1)`이다. 

`(P_2 - P_1)`는 정책의 효과 + @이고 `(S_2 - S_1)`는 기간의 특성을 의미한다. 즉, 정책을 적용하지 않았음에도 기간 특성에 따른 증가한 매출을 의미한다.
즉, @를 기간 특성이라 가정하고, (정책의 효과 + @ - 기간 특성에 따른 매출 증가량)이 본 정책의 온전한 효과임을 추정한 것이다.


![alt text]({{ site.baseurl }}/assets/did.png "Profile Picture"){:.profile}
